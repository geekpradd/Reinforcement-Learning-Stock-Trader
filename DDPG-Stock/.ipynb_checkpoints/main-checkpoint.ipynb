{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from tqdm.notebook import tqdm\n",
    "COLAB = False\n",
    "if not COLAB:\n",
    "    import os\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Input\n",
    "from environment_ddpg import StockEnv, create_stock_env\n",
    "from utils import ReplayBuffer, OrnsteinUhlenbeckActionNoise\n",
    "path_base = \"models/\"\n",
    "RESUME = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor:\n",
    "    def __init__(self, params):\n",
    "        self.output_range = params[\"output_range\"]\n",
    "        self.hidden_layers = params[\"actor_hidden_layers\"]\n",
    "        self.state_dimensions = params[\"state_dimensions\"]\n",
    "        self.action_dimensions = params[\"action_dimensions\"]\n",
    "        self.actor = self.model()\n",
    "        \n",
    "    def model(self):\n",
    "        inputs = Input(shape=(1, self.state_dimensions))\n",
    "        x = Lambda(lambda x: x)(inputs)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = Dense(layer, activation='relu')(x)\n",
    "        x = Dense(self.action_dimensions, activation='tanh')(x)\n",
    "        x = Lambda(lambda x: x*self.output_range)(x)\n",
    "        model = tf.keras.Model(inputs = inputs, outputs = x)\n",
    "        return model\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state_tensor = tf.Variable(shape = state.shape, initial_value = state)\n",
    "        return (self.actor(state_tensor)).numpy()\n",
    "\n",
    "    def save_weights(self):\n",
    "        self.actor.save_weights(path_base + \"actor.h5\")\n",
    "               \n",
    "    def load_weights(self):\n",
    "        self.actor.load_weights(path_base + \"actor.h5\")\n",
    "        \n",
    "    \n",
    "class Critic:\n",
    "    def __init__(self, params):\n",
    "        self.hidden_layers = params[\"critic_hidden_layers\"]\n",
    "        self.state_dimensions = params[\"state_dimensions\"]\n",
    "        self.action_dimensions = params[\"action_dimensions\"]\n",
    "        self.optimizer = params[\"critic_optimizer\"]\n",
    "        self.critic_online = self.model()\n",
    "        self.critic_target = self.model()\n",
    "\n",
    "\n",
    "    def model(self):\n",
    "        input_a = Input(shape = (1, self.state_dimensions))\n",
    "        input_b = Input(shape = (1, self.action_dimensions))\n",
    "        x = concatenate([input_a, input_b], axis=-1)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = Dense(layer, activation='relu')(x)\n",
    "        x = Dense(1, activation='linear')(x)\n",
    "        model = tf.keras.Model(inputs=[input_a, input_b], outputs = x)\n",
    "        model.compile(loss='mse', optimizer=self.optimizer)\n",
    "        return model\n",
    "    \n",
    "    def save_weights(self):\n",
    "        self.critic_online.save_weights(path_base + \"critic_online.h5\")\n",
    "        self.critic_target.save_weights(path_base +  \"critic_target.h5\")\n",
    "               \n",
    "    def load_weights(self):\n",
    "        self.critic_online.load_weights(path_base + \"critic_online.h5\")\n",
    "        self.critic_target.load_weights(path_base + \"critic_target.h5\")\n",
    "\n",
    "    def get_qvalues(self, state_array, action_array, online=True):\n",
    "        state_tensor = tf.Variable(shape = state_array.shape, initial_value = state_array)\n",
    "        action_tensor = tf.Variable(shape = action_array.shape, initial_value = action_array)\n",
    "        return (self.critic_online([state_tensor, action_tensor]).numpy() if online else self.critic_target([state_tensor, action_tensor]).numpy())\n",
    "    \n",
    "    def call(self, state_tensor, action_tensor, online = True):\n",
    "        return (self.critic_online([state_tensor, action_tensor]) if online else self.critic_target([state_tensor, action_tensor]))\n",
    "    def merge_networks(self, tau):\n",
    "        self.critic_target.set_weights(tau*np.array(self.critic_online.get_weights())\n",
    "                                                                    + (1-tau)*np.array(self.critic_target.get_weights()))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, params, test=False):\n",
    "        self.test = test\n",
    "        self.actor = Actor(params)\n",
    "        self.critic = Critic(params)\n",
    "        self.buffer = ReplayBuffer(params[\"buffer_size\"])\n",
    "        self.state_dimensions = params[\"state_dimensions\"]\n",
    "        self.action_dimensions = params[\"action_dimensions\"]\n",
    "        self.discount = params[\"discount\"]\n",
    "        self.action_range = params[\"output_range\"]\n",
    "        self.save_frequency = params[\"save_frequency\"]\n",
    "        self.batch_size = params[\"batch_size\"]\n",
    "        self.optimizer = params[\"actor_optimizer\"]\n",
    "        self.tau = params[\"tau\"]\n",
    "        self.step = 0\n",
    "        self.noise_func =  OrnsteinUhlenbeckActionNoise(mu=np.zeros(params[\"action_dimensions\"]))\n",
    "        if RESUME:\n",
    "            self.load_networks()\n",
    "        \n",
    "    def agent_start(self, observation):\n",
    "        observation = np.reshape(observation, (1, self.state_dimensions))\n",
    "        act = np.squeeze(self.actor.get_action(observation))\n",
    "        if not self.test:\n",
    "            action = self.clip_action(act + self.noise_func())\n",
    "        else:\n",
    "            action = [self.clip_action(act)]\n",
    "        self.prev_state = observation\n",
    "        self.prev_action = action\n",
    "        return action \n",
    "\n",
    "    def clip_action(self, action):\n",
    "        if abs(action) > self.action_range:\n",
    "            action *= abs(self.action_range)/abs(action)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def agent_step(self, reward, observation):\n",
    "        observation = np.reshape(observation, (1, self.state_dimensions))\n",
    "        if not self.test:\n",
    "            relay = (self.prev_state, self.prev_action, reward, observation)\n",
    "            self.buffer.add(relay)\n",
    "        self.prev_state = observation\n",
    "        act = np.squeeze(self.actor.get_action(observation))\n",
    "        if not self.test:\n",
    "            self.prev_action = self.clip_action(act + self.noise_func())\n",
    "            self.train(self.batch_size)\n",
    "        else:\n",
    "            self.prev_action = [self.clip_action(act)]\n",
    "        \n",
    "        return self.prev_action \n",
    "    \n",
    "    def save_networks(self):\n",
    "        self.actor.save_weights()\n",
    "        self.critic.save_weights()\n",
    "\n",
    "    def load_networks(self):\n",
    "        self.actor.load_weights()\n",
    "        self.critic.load_weights()\n",
    "\n",
    "\n",
    "    def train(self, sample_size):\n",
    "        self.step += 1\n",
    "        batch, batch_size = self.buffer.sample(sample_size)\n",
    "\n",
    "        state_array = np.array([ element[3] for element in batch])\n",
    "        action_array = self.actor.get_action(state_array)\n",
    "        prev_state_array = np.array([ element[0] for element in batch])\n",
    "        prev_action_array = np.array([ [[element[2]]] for element in batch])\n",
    "        output = self.critic.get_qvalues(state_array, action_array, False)\n",
    "        output = np.array([element[2] + self.discount*out[0] for element, out in zip(batch, output)])\n",
    "        self.critic.critic_online.fit([state_array, action_array], output, verbose=0)\n",
    "\n",
    "        prev_state_tensor = tf.Variable(shape = prev_state_array.shape, initial_value = prev_state_array)\n",
    "        prev_action_tensor = tf.Variable(shape = prev_action_array.shape, initial_value = prev_action_array)\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as g:\n",
    "            g.watch(prev_action_tensor) \n",
    "            g.watch(prev_state_tensor)\n",
    "            value = self.critic.call(prev_state_tensor, prev_action_tensor)\n",
    "            action = self.actor.actor(prev_state_tensor)\n",
    "            \n",
    "        gradient = -tf.squeeze(g.gradient(value, prev_action_tensor))\n",
    "        gradient = tf.cast(gradient, tf.float32)\n",
    "        gradient_actor = g.gradient(action, self.actor.actor.trainable_weights, gradient)\n",
    "        gradient_actor = list(map(lambda x: tf.math.divide(x, batch_size), gradient_actor))\n",
    "        self.optimizer.apply_gradients(zip(gradient_actor, self.actor.actor.trainable_weights))\n",
    "        self.critic.merge_networks(self.tau)\n",
    "\n",
    "        if self.step%self.save_frequency == 0:\n",
    "            self.save_networks()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_PARAMS = {\n",
    "\t\"output_range\": 1,\n",
    "\t\"actor_hidden_layers\": [30, 8],\n",
    "\t\"critic_hidden_layers\": [30, 8],\n",
    "\t\"state_dimensions\": 4,\n",
    "\t\"action_dimensions\": 1,\n",
    "\t\"critic_optimizer\": tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "\t\"actor_optimizer\": tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "\t\"batch_size\": 64,\n",
    "\t\"buffer_size\":1000000,\n",
    "\t\"discount\": 0.99,\n",
    "\t\"tau\": 0.001,\n",
    "\t\"save_frequency\": 100\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'd' does not exist: b'd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-94fc7d1148c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Train LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAGENT_PARAMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mITERATIONS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_stock_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/AAPL.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mITERATIONS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Iteration: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c69797d2c434>\u001b[0m in \u001b[0;36mcreate_stock_env\u001b[0;34m(locations, train)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_stock_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c69797d2c434>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_stock_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'd' does not exist: b'd'"
     ]
    }
   ],
   "source": [
    "## Train LOOP\n",
    "agent = Agent(AGENT_PARAMS)\n",
    "env, ITERATIONS = create_stock_env(\"data/AAPL.csv\")\n",
    "ITERATIONS = 20000\n",
    "pbar = tqdm(desc=\"Iteration: \", total=ITERATIONS)\n",
    "action = agent.agent_start(env.reset())\n",
    "observation, reward, done, info = env.step(action[0])\n",
    "profit = np.zeros(ITERATIONS)\n",
    "prev_profit = 0\n",
    "for _ in range(ITERATIONS):\n",
    "    action = agent.agent_step(reward, observation)\n",
    "    observation, reward, done, info = env.step(action[0])\n",
    "    profit[i] += reward + prev_profit\n",
    "    prev_profit += reward\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST LOOP\n",
    "agent = Agent(AGENT_PARAMS, test=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "files = [\"nifty50.csv\"]\n",
    "final_profit_dict = {}\n",
    "for num_iter, file in enumerate(files):\n",
    "    print (\"At \" + file)\n",
    "    env, ITERATIONS = create_stock_env(\"nifty/{0}\".format(file), False)\n",
    "    ITERATIONS = 3000\n",
    "    profit = np.zeros(ITERATIONS)\n",
    "    prev_profit = 0 \n",
    "    obs = env.reset()\n",
    "    prev_profit = 0\n",
    "    action = agent.agent_start(env.reset())\n",
    "    observation, reward, done, info = env.step(action[0])\n",
    "    pbar = tqdm(desc=\"Iteration: \", total=ITERATIONS)\n",
    "    for i in range(ITERATIONS):\n",
    "        action = agent.agent_step(reward, observation)\n",
    "        observation, reward, done, info = env.step(action[0])\n",
    "        profit[i] += reward + prev_profit\n",
    "        prev_profit +=reward\n",
    "        pbar.update(1)\n",
    "    plt.figure() \n",
    "    plt.plot(profit)\n",
    "    plt.title(file + \" profit: \"+str(profit[-1]))\n",
    "    plt.show()\n",
    "    final_profit_dict[file] = profit[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
