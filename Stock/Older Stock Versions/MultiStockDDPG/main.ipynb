{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from tqdm.notebook import tqdm\n",
    "COLAB = False\n",
    "if not COLAB:\n",
    "    import os\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Input\n",
    "from utils import ReplayBuffer, OrnsteinUhlenbeckActionNoise\n",
    "path_base = \"models/\"\n",
    "RESUME = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime as dt\n",
    "\n",
    "MAX_Money = 100000\n",
    "class StockEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self,dfs, train, number=1, **kwargs):\n",
    "        super(StockEnv,self).__init__()\n",
    "        self.train = train\n",
    "        self.MAX_shares = 2147483647\n",
    "        self.Min_Brokerage = 30\n",
    "        self.count = number\n",
    "        self.Brokerage_rate = 0.001\n",
    "        \n",
    "        if \"balance\" in kwargs.keys():\n",
    "            Max_Money = kwargs[\"balance\"]\n",
    "        if \"Max_Shares\" in kwargs.keys():\n",
    "            self.MAX_shares = kwargs[\"Shares\"]\n",
    "        if \"Broke_limit\" in kwargs.keys():\n",
    "            self.Min_Brokerage = kwargs[\"Broke_limit\"]\n",
    "        if \"Broke_rate\" in kwargs.keys():\n",
    "            self.Brokerage_rate = kwargs[\"Broke_rate\"]\n",
    "        \n",
    "        self.dfs = dfs\n",
    "        self.action_space = spaces.Box(low = np.array([-1]), high = np.array([1]), dtype = np.float16)\n",
    "        lower = [0]*number\n",
    "        higher = [1]*number\n",
    "        self.observation_space = spaces.Box(low=np.array(lower),high=np.array(higher),dtype=np.float32)\n",
    "    \n",
    "    def _get_prices(self):\n",
    "#         print (\"Day {0}\".format(self.df.loc[self.current_step,\"Date\"]))\n",
    "#         print (\"low: {0} high: {1}\".format(self.df.loc[self.current_step,\"Open\"],self.df.loc[self.current_step,\"Close\"]))\n",
    "        return np.array([np.random.uniform(df.loc[self.current_step,\"Open\"], df.loc[self.current_step,\"Close\"]) for df in self.dfs])\n",
    "    \n",
    "    def _observe(self, prices):\n",
    "        frame = prices\n",
    "        frame = frame / self.highest_price\n",
    "        info = {\n",
    "            'balance' : self.balance,\n",
    "            'highest_price': self.highest_price,\n",
    "            'current_price': self.current_prices,\n",
    "            #'time': self.df.loc[self.current_step,'time_stamp'],\n",
    "            'shares_held': self.shares_held,\n",
    "            'max_worth': self.max_net_worth,\n",
    "            'broke_limit': self.Min_Brokerage,\n",
    "            'broke_rate': self.Brokerage_rate\n",
    "        }\n",
    "        \n",
    "        return frame, info\n",
    "        \n",
    "    def reset(self,balance = MAX_Money,**kwargs):\n",
    "        if \"balance\" in kwargs.keys():\n",
    "            Max_Money = kwargs[\"balance\"]\n",
    "        if \"Max_Shares\" in kwargs.keys():\n",
    "            self.MAX_shares = kwargs[\"Shares\"]\n",
    "        if \"Broke_limit\" in kwargs.keys():\n",
    "            self.Min_Brokerage = kwargs[\"Broke_limit\"]\n",
    "        if \"Broke_rate\" in kwargs.keys():\n",
    "            self.Brokerage_rate = kwargs[\"Broke_rate\"]\n",
    "        \n",
    "        if self.train:\n",
    "            self.current_step = np.random.randint(0,len(self.dfs[0].loc[:,'Open'].values)-1)\n",
    "        else:\n",
    "            self.current_step = 0\n",
    "       \n",
    "        self.balance = balance\n",
    "        self.shares_held = np.array([0]*self.count)\n",
    "        self.current_prices = self._get_prices() \n",
    "        self.net_worth = self.balance + sum(self.shares_held*self.current_prices)\n",
    "        self.initial_worth = self.net_worth\n",
    "        self.max_net_worth = self.net_worth\n",
    "        self.highest_price = np.max(self.current_prices)\n",
    "        frame,_ =  self._observe(self.current_prices)\n",
    "        return frame\n",
    "    \n",
    "    def _broke(self,amount):\n",
    "        return max(amount * self.Brokerage_rate,self.Min_Brokerage)\n",
    "    \n",
    "    def _take_action(self, action_vector):\n",
    "        self.current_prices = self._get_prices()\n",
    "        self.highest_price = max(self.highest_price,np.max(self.current_prices))\n",
    "        action_vector  = action_vector*self.MAX_shares\n",
    "        for i in range(self.count):\n",
    "            if action_vector[i] < 0:\n",
    "                # sell\n",
    "                action_vector[i] = -1*action_vector[i]\n",
    "                if action_vector[i] > self.shares_held[i]:\n",
    "                    action_vector[i] = self.shares_held[i]\n",
    "                amount_gained = action_vector[i]*self.current_prices[i]\n",
    "                broke = self._broke(amount_gained)\n",
    "                amount_gained -= broke\n",
    "                if self.balance + amount_gained < 0:\n",
    "                    a1 = np.floor(self.balance/((self.Brokerage_rate-1)*self.current_prices[i]))\n",
    "                    action = np.floor(-(self.balance-self.Min_Brokerage)/self.current_prices[i])\n",
    "                    if self._broke(a1*self.current_prices[i]) == a1*self.current_prices[i]*self.Brokerage_rate:\n",
    "                        action_vector[i] = max(a1,action_vector[i])\n",
    "                    action_vector[i] = max(action_vector[i],0)\n",
    "                    amount_gained = action_vector[i]*self.current_prices[i]\n",
    "                    amount_gained -= self._broke(amount_gained)\n",
    "                self.balance +=amount_gained\n",
    "                self.shares_held[i] = self.shares_held[i]-action_vector[i]\n",
    "            elif action_vector[i]>0:\n",
    "                #buy\n",
    "                amount_required = self.current_prices[i]*action_vector[i] + self._broke(self.current_prices[i]*action_vector[i])\n",
    "                if amount_required > self.balance:\n",
    "                    a1 = np.floor(self.balance/((self.Brokerage_rate+1)*self.current_prices[i]))\n",
    "                    action_vector[i] = np.floor((self.balance-self.Min_Brokerage)/self.current_prices[i])\n",
    "                    if self._broke(a1*self.current_prices[i]) == a1*self.current_prices[i]*self.Brokerage_rate:\n",
    "                        action_vector[i] = max(a1,action_vector[i])\n",
    "                    action_vector[i] = max(action_vector[i],0)\n",
    "                    amount_required = action_vector[i]*self.current_prices[i]\n",
    "                    amount_required -= self._broke(amount_required)\n",
    "                self.balance -= amount_required\n",
    "                self.shares_held[i] += action_vector[i]\n",
    "        reward = self.balance + sum(self.shares_held* self.current_prices) - self.net_worth\n",
    "        self.net_worth = self.balance + sum(self.shares_held* self.current_prices)\n",
    "        if self.net_worth > self.max_net_worth:\n",
    "            self.max_net_worth = self.net_worth\n",
    "        return reward, self.current_prices\n",
    "            \n",
    "    def step(self, action):\n",
    "        reward, prices = self._take_action(action)\n",
    "        self.current_step+=1\n",
    "        if self.current_step > len(self.dfs[0].loc[:,'Open'].values)-1:\n",
    "            self.current_step = 0\n",
    "        \n",
    "        done = self.net_worth<=0\n",
    "        obs, info = self._observe(prices)\n",
    "        \n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def render(self, mode='human', close = False):\n",
    "        profit = self.net_worth - self.initial_worth\n",
    "        print(f'Step: {self.current_step}')\n",
    "        print(f'Net Worth:{self.net_worth}')\n",
    "        print(f'Profit: {profit}')\n",
    "\n",
    "\n",
    "def create_stock_env(locations, train=True):\n",
    "    dfs = [pd.read_csv(location) for location in locations]\n",
    "    for df in dfs:\n",
    "        (df.sort_values(\"Date\"))\n",
    "    return StockEnv(dfs, train, len(locations)), dfs[0].shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor:\n",
    "    def __init__(self, params):\n",
    "        self.output_range = params[\"output_range\"]\n",
    "        self.hidden_layers = params[\"actor_hidden_layers\"]\n",
    "        self.state_dimensions = params[\"state_dimensions\"]\n",
    "        self.action_dimensions = params[\"action_dimensions\"]\n",
    "        self.actor = self.model()\n",
    "        \n",
    "    def model(self):\n",
    "        inputs = Input(shape=(1, self.state_dimensions))\n",
    "        x = Lambda(lambda x: x)(inputs)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = Dense(layer, activation='relu')(x)\n",
    "        x = Dense(self.action_dimensions, activation='tanh')(x)\n",
    "        x = Lambda(lambda x: x*self.output_range)(x)\n",
    "        model = tf.keras.Model(inputs = inputs, outputs = x)\n",
    "        return model\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state_tensor = tf.Variable(shape = state.shape, initial_value = state)\n",
    "        return (self.actor(state_tensor)).numpy()\n",
    "\n",
    "    def save_weights(self):\n",
    "        self.actor.save_weights(path_base + \"actor.h5\")\n",
    "               \n",
    "    def load_weights(self):\n",
    "        self.actor.load_weights(path_base + \"actor.h5\")\n",
    "        \n",
    "    \n",
    "class Critic:\n",
    "    def __init__(self, params):\n",
    "        self.hidden_layers = params[\"critic_hidden_layers\"]\n",
    "        self.state_dimensions = params[\"state_dimensions\"]\n",
    "        self.action_dimensions = params[\"action_dimensions\"]\n",
    "        self.optimizer = params[\"critic_optimizer\"]\n",
    "        self.critic_online = self.model()\n",
    "        self.critic_target = self.model()\n",
    "\n",
    "\n",
    "    def model(self):\n",
    "        input_a = Input(shape = (1, self.state_dimensions))\n",
    "        input_b = Input(shape = (1, self.action_dimensions))\n",
    "        x = concatenate([input_a, input_b], axis=-1)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = Dense(layer, activation='relu')(x)\n",
    "        x = Dense(1, activation='linear')(x)\n",
    "        model = tf.keras.Model(inputs=[input_a, input_b], outputs = x)\n",
    "        model.compile(loss='mse', optimizer=self.optimizer)\n",
    "        return model\n",
    "    \n",
    "    def save_weights(self):\n",
    "        self.critic_online.save_weights(path_base + \"critic_online.h5\")\n",
    "        self.critic_target.save_weights(path_base +  \"critic_target.h5\")\n",
    "               \n",
    "    def load_weights(self):\n",
    "        self.critic_online.load_weights(path_base + \"critic_online.h5\")\n",
    "        self.critic_target.load_weights(path_base + \"critic_target.h5\")\n",
    "\n",
    "    def get_qvalues(self, state_array, action_array, online=True):\n",
    "        state_tensor = tf.Variable(shape = state_array.shape, initial_value = state_array)\n",
    "        action_tensor = tf.Variable(shape = action_array.shape, initial_value = action_array)\n",
    "        return (self.critic_online([state_tensor, action_tensor]).numpy() if online else self.critic_target([state_tensor, action_tensor]).numpy())\n",
    "    \n",
    "    def call(self, state_tensor, action_tensor, online = True):\n",
    "        return (self.critic_online([state_tensor, action_tensor]) if online else self.critic_target([state_tensor, action_tensor]))\n",
    "    def merge_networks(self, tau):\n",
    "        self.critic_target.set_weights(tau*np.array(self.critic_online.get_weights())\n",
    "                                                                    + (1-tau)*np.array(self.critic_target.get_weights()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, params, test=False):\n",
    "        self.test = test\n",
    "        self.actor = Actor(params)\n",
    "        self.critic = Critic(params)\n",
    "        self.buffer = ReplayBuffer(params[\"buffer_size\"])\n",
    "        self.state_dimensions = params[\"state_dimensions\"]\n",
    "        self.action_dimensions = params[\"action_dimensions\"]\n",
    "        self.discount = params[\"discount\"]\n",
    "        self.action_range = params[\"output_range\"]\n",
    "        self.save_frequency = params[\"save_frequency\"]\n",
    "        self.batch_size = params[\"batch_size\"]\n",
    "        self.optimizer = params[\"actor_optimizer\"]\n",
    "        self.tau = params[\"tau\"]\n",
    "        self.step = 0\n",
    "        self.noise_func =  OrnsteinUhlenbeckActionNoise(mu=np.zeros(params[\"action_dimensions\"]))\n",
    "        if RESUME:\n",
    "            self.load_networks()\n",
    "        \n",
    "    def agent_start(self, observation):\n",
    "        observation = np.reshape(observation, (1, self.state_dimensions))\n",
    "        act = np.squeeze(self.actor.get_action(observation))\n",
    "        if not self.test:\n",
    "            for i in range(act.shape[0]):\n",
    "                act[i] = np.squeeze(self.clip_action((act[i] + self.noise_func())[0]))\n",
    "        else:\n",
    "            for i in range(act.shape[0]):\n",
    "                act[i] = np.squeeze(self.clip_action(act[i]))\n",
    "        self.prev_state = observation\n",
    "        self.prev_action = act\n",
    "        return act\n",
    "\n",
    "    def clip_action(self, action):\n",
    "        if abs(action) > self.action_range:\n",
    "            action *= abs(self.action_range)/abs(action)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def agent_step(self, reward, observation):\n",
    "        observation = np.reshape(observation, (1, self.state_dimensions))\n",
    "        if not self.test:\n",
    "            relay = (self.prev_state, self.prev_action, reward, observation)\n",
    "            self.buffer.add(relay)\n",
    "        self.prev_state = observation\n",
    "        act = np.squeeze(self.actor.get_action(observation))\n",
    "        if not self.test:\n",
    "            for i in range(act.shape[0]):\n",
    "                act[i] = np.squeeze(self.clip_action((act[i] + self.noise_func())[0]))\n",
    "            self.train(self.batch_size)\n",
    "        else:\n",
    "            for i in range(act.shape[0]):\n",
    "                act[i] = np.squeeze(self.clip_action(act[i]))\n",
    "        \n",
    "        self.prev_action = act\n",
    "        return self.prev_action \n",
    "    \n",
    "    def save_networks(self):\n",
    "        self.actor.save_weights()\n",
    "        self.critic.save_weights()\n",
    "\n",
    "    def load_networks(self):\n",
    "        self.actor.load_weights()\n",
    "        self.critic.load_weights()\n",
    "\n",
    "\n",
    "    def train(self, sample_size):\n",
    "        self.step += 1\n",
    "        batch, batch_size = self.buffer.sample(sample_size)\n",
    "\n",
    "        state_array = np.array([ element[3] for element in batch])\n",
    "        action_array = self.actor.get_action(state_array)\n",
    "        prev_state_array = np.array([ element[0] for element in batch])\n",
    "        prev_action_array = np.array([ [[element[2]]] for element in batch])\n",
    "        output = self.critic.get_qvalues(state_array, action_array, False)\n",
    "        output = np.array([element[2] + self.discount*out[0] for element, out in zip(batch, output)])\n",
    "        self.critic.critic_online.fit([state_array, action_array], output, verbose=0)\n",
    "\n",
    "        prev_state_tensor = tf.Variable(shape = prev_state_array.shape, initial_value = prev_state_array)\n",
    "        prev_action_tensor = tf.Variable(shape = prev_action_array.shape, initial_value = prev_action_array)\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as g:\n",
    "            g.watch(prev_action_tensor) \n",
    "            g.watch(prev_state_tensor)\n",
    "            value = self.critic.call(prev_state_tensor, prev_action_tensor)\n",
    "            action = self.actor.actor(prev_state_tensor)\n",
    "            \n",
    "        gradient = -tf.squeeze(g.gradient(value, prev_action_tensor))\n",
    "        gradient = tf.cast(gradient, tf.float32)\n",
    "        gradient_actor = g.gradient(action, self.actor.actor.trainable_weights, gradient)\n",
    "        gradient_actor = list(map(lambda x: tf.math.divide(x, batch_size), gradient_actor))\n",
    "        self.optimizer.apply_gradients(zip(gradient_actor, self.actor.actor.trainable_weights))\n",
    "        self.critic.merge_networks(self.tau)\n",
    "\n",
    "        if self.step%self.save_frequency == 0:\n",
    "            self.save_networks()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_PARAMS = {\n",
    "\t\"output_range\": 1,\n",
    "\t\"actor_hidden_layers\": [60, 16],\n",
    "\t\"critic_hidden_layers\": [60, 16],\n",
    "\t\"state_dimensions\": 29,\n",
    "\t\"action_dimensions\": 29,\n",
    "\t\"critic_optimizer\": tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "\t\"actor_optimizer\": tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "\t\"batch_size\": 64,\n",
    "\t\"buffer_size\":1000000,\n",
    "\t\"discount\": 0.99,\n",
    "\t\"tau\": 0.001,\n",
    "\t\"save_frequency\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = [\"train/\" + f for f in os.listdir(\"train/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "env, stamps = create_stock_env(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35321339, 0.39572086, 0.21128619, 0.50573689, 0.24027794,\n",
       "       0.48543738, 0.54282275, 0.469029  , 0.95749591, 0.31165276,\n",
       "       0.75146567, 0.4360287 , 0.21634115, 0.47254771, 0.15718709,\n",
       "       0.66458452, 0.54935278, 0.18102918, 0.64808163, 0.27973536,\n",
       "       0.30922683, 0.46164503, 0.52661648, 1.        , 0.13033785,\n",
       "       0.32989886, 0.48528385, 0.45077625, 0.25508728])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.35410773, 0.39586117, 0.2113022 , 0.50352776, 0.24048512,\n",
       "        0.48505872, 0.54411025, 0.46943028, 0.95431472, 0.31196466,\n",
       "        0.75236174, 0.43602572, 0.21635295, 0.47195392, 0.15709856,\n",
       "        0.66363665, 0.54937729, 0.18132001, 0.64715962, 0.27972499,\n",
       "        0.30994882, 0.46097375, 0.52658894, 0.99975684, 0.13037384,\n",
       "        0.32993829, 0.48543199, 0.45078721, 0.25463368]),\n",
       " 939.9289812043135,\n",
       " False,\n",
       " {'balance': 93.070719564354,\n",
       "  'highest_price': 192.8908944820442,\n",
       "  'current_price': array([ 68.30415667,  76.35801585,  40.75827094,  97.12592065,\n",
       "          46.38738898,  93.56340966, 104.95391245,  90.54882714,\n",
       "         184.07862064,  60.17514175, 145.12372903,  84.10539197,\n",
       "          41.73251465,  91.0356132 ,  30.30288241, 128.00946733,\n",
       "         105.96987675,  34.97497988, 124.83119744,  53.95640372,\n",
       "          59.78630418,  88.91763907, 101.57421258, 192.84399167,\n",
       "          25.1479264 ,  63.64209218,  93.6354102 ,  86.9527473 ,\n",
       "          49.11651816]),\n",
       "  'shares_held': array([1463,    1,    2,    0,    1,    0,    0,    1,    0,    1,    0,\n",
       "            1,    0,    0,    3,    0,    0,    2,    0,    1,    0,    0,\n",
       "            1,    0,    3,    0,    0,    1,    0]),\n",
       "  'max_worth': 100939.92898120431,\n",
       "  'broke_limit': 30,\n",
       "  'broke_rate': 0.001})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580596c3c0fe4dc28eebe7a2a8797403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration: ', max=20000, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [1,30], In[1]: [58,60] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-935492a38bd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprev_profit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprofit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprev_profit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-a6c52ff254e7>\u001b[0m in \u001b[0;36magent_step\u001b[0;34m(self, reward, observation)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-a6c52ff254e7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sample_size)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_action_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_state_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_state_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_action_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_state_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-3bdfc71a8221>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, state_tensor, action_tensor, online)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_online\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0monline\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         self.critic_target.set_weights(tau*np.array(self.critic_online.get_weights())\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    717\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    718\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0;31m# Broadcasting is required for the inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m       \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   4344\u001b[0m     b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n\u001b[1;32m   4345\u001b[0m         b, b_axes, True)\n\u001b[0;32m-> 4346\u001b[0;31m     \u001b[0mab_matmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4348\u001b[0m       if (ab_matmul.get_shape().is_fully_defined() and\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2984\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5575\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5576\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5577\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5578\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5579\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [1,30], In[1]: [58,60] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "agent = Agent(AGENT_PARAMS)\n",
    "ITERATIONS = 20000\n",
    "pbar = tqdm(desc=\"Iteration: \", total=ITERATIONS)\n",
    "action = agent.agent_start(env.reset())\n",
    "observation, reward, done, info = env.step(action)\n",
    "profit = np.zeros(ITERATIONS)\n",
    "prev_profit = 0\n",
    "for _ in range(ITERATIONS):\n",
    "    action = agent.agent_step(reward, observation)\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    profit[i] += reward + prev_profit\n",
    "    prev_profit += reward\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
