{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from tqdm.notebook import tqdm\n",
    "COLAB = False\n",
    "if not COLAB:\n",
    "    import os\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Input\n",
    "from environment import StockEnv, create_stock_env\n",
    "from utils import ReplayBuffer, OrnsteinUhlenbeckActionNoise\n",
    "path_base = \"models/\"\n",
    "RESUME = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor:\n",
    "    def __init__(self, params):\n",
    "        self.output_range = params[\"output_range\"]\n",
    "        self.hidden_layers = params[\"actor_hidden_layers\"]\n",
    "        self.state_dimensions = params[\"state_dimensions\"]\n",
    "        self.action_dimensions = params[\"action_dimensions\"]\n",
    "        self.actor = self.model()\n",
    "        \n",
    "    def model(self):\n",
    "        inputs = Input(shape=(1, self.state_dimensions))\n",
    "        x = Lambda(lambda x: x)(inputs)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = Dense(layer, activation='relu')(x)\n",
    "        x = Dense(self.action_dimensions, activation='tanh')(x)\n",
    "        x = Lambda(lambda x: x*self.output_range)(x)\n",
    "        model = tf.keras.Model(inputs = inputs, outputs = x)\n",
    "        return model\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state_tensor = tf.Variable(shape = state.shape, initial_value = state)\n",
    "        return (self.actor(state_tensor)).numpy()\n",
    "\n",
    "    def save_weights(self):\n",
    "        self.actor.save_weights(path_base + \"actor.h5\")\n",
    "               \n",
    "    def load_weights(self):\n",
    "        self.actor.load_weights(path_base + \"actor.h5\")\n",
    "        \n",
    "    \n",
    "class Critic:\n",
    "    def __init__(self, params):\n",
    "        self.hidden_layers = params[\"critic_hidden_layers\"]\n",
    "        self.state_dimensions = params[\"state_dimensions\"]\n",
    "        self.action_dimensions = params[\"action_dimensions\"]\n",
    "        self.optimizer = params[\"critic_optimizer\"]\n",
    "        self.critic_online = self.model()\n",
    "        self.critic_target = self.model()\n",
    "\n",
    "\n",
    "    def model(self):\n",
    "        input_a = Input(shape = (1, self.state_dimensions))\n",
    "        input_b = Input(shape = (1, self.action_dimensions))\n",
    "        x = concatenate([input_a, input_b], axis=-1)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = Dense(layer, activation='relu')(x)\n",
    "        x = Dense(1, activation='linear')(x)\n",
    "        model = tf.keras.Model(inputs=[input_a, input_b], outputs = x)\n",
    "        model.compile(loss='mse', optimizer=self.optimizer)\n",
    "        return model\n",
    "    \n",
    "    def save_weights(self):\n",
    "        self.critic_online.save_weights(path_base + \"critic_online.h5\")\n",
    "        self.critic_target.save_weights(path_base +  \"critic_target.h5\")\n",
    "               \n",
    "    def load_weights(self):\n",
    "        self.critic_online.load_weights(path_base + \"critic_online.h5\")\n",
    "        self.critic_target.load_weights(path_base + \"critic_target.h5\")\n",
    "\n",
    "    def get_qvalues(self, state_array, action_array, online=True):\n",
    "        state_tensor = tf.Variable(shape = state_array.shape, initial_value = state_array)\n",
    "        action_tensor = tf.Variable(shape = action_array.shape, initial_value = action_array)\n",
    "        return (self.critic_online([state_tensor, action_tensor]).numpy() if online else self.critic_target([state_tensor, action_tensor]).numpy())\n",
    "    \n",
    "    def call(self, state_tensor, action_tensor, online = True):\n",
    "        return (self.critic_online([state_tensor, action_tensor]) if online else self.critic_target([state_tensor, action_tensor]))\n",
    "    def merge_networks(self, tau):\n",
    "        self.critic_target.set_weights(tau*np.array(self.critic_online.get_weights())\n",
    "                                                                    + (1-tau)*np.array(self.critic_target.get_weights()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, params, test=False):\n",
    "        self.test = test\n",
    "        self.actor = Actor(params)\n",
    "        self.critic = Critic(params)\n",
    "        self.buffer = ReplayBuffer(params[\"buffer_size\"])\n",
    "        self.state_dimensions = params[\"state_dimensions\"]\n",
    "        self.action_dimensions = params[\"action_dimensions\"]\n",
    "        self.discount = params[\"discount\"]\n",
    "        self.action_range = params[\"output_range\"]\n",
    "        self.save_frequency = params[\"save_frequency\"]\n",
    "        self.batch_size = params[\"batch_size\"]\n",
    "        self.optimizer = params[\"actor_optimizer\"]\n",
    "        self.tau = params[\"tau\"]\n",
    "        self.step = 0\n",
    "        self.noise_func =  OrnsteinUhlenbeckActionNoise(mu=np.zeros(params[\"action_dimensions\"]))\n",
    "        if RESUME:\n",
    "            self.load_networks()\n",
    "        \n",
    "    def agent_start(self, observation):\n",
    "        observation = np.reshape(observation, (1, self.state_dimensions))\n",
    "        act = np.squeeze(self.actor.get_action(observation))\n",
    "        if not self.test:\n",
    "            action = self.clip_action(act + self.noise_func())\n",
    "        else:\n",
    "            action = [self.clip_action(act)]\n",
    "        self.prev_state = observation\n",
    "        self.prev_action = action\n",
    "        return action \n",
    "\n",
    "    def clip_action(self, action):\n",
    "        if abs(action) > self.action_range:\n",
    "            action *= abs(self.action_range)/abs(action)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def agent_step(self, reward, observation):\n",
    "        observation = np.reshape(observation, (1, self.state_dimensions))\n",
    "        if not self.test:\n",
    "            relay = (self.prev_state, self.prev_action, reward, observation)\n",
    "            self.buffer.add(relay)\n",
    "        self.prev_state = observation\n",
    "        act = np.squeeze(self.actor.get_action(observation))\n",
    "        if not self.test:\n",
    "            self.prev_action = self.clip_action(act + self.noise_func())\n",
    "            self.train(self.batch_size)\n",
    "        else:\n",
    "            self.prev_action = [self.clip_action(act)]\n",
    "        \n",
    "        return self.prev_action \n",
    "    \n",
    "    def save_networks(self):\n",
    "        self.actor.save_weights()\n",
    "        self.critic.save_weights()\n",
    "\n",
    "    def load_networks(self):\n",
    "        self.actor.load_weights()\n",
    "        self.critic.load_weights()\n",
    "\n",
    "\n",
    "    def train(self, sample_size):\n",
    "        self.step += 1\n",
    "        batch, batch_size = self.buffer.sample(sample_size)\n",
    "\n",
    "        state_array = np.array([ element[3] for element in batch])\n",
    "        action_array = self.actor.get_action(state_array)\n",
    "        prev_state_array = np.array([ element[0] for element in batch])\n",
    "        prev_action_array = np.array([ [[element[2]]] for element in batch])\n",
    "        output = self.critic.get_qvalues(state_array, action_array, False)\n",
    "        output = np.array([element[2] + self.discount*out[0] for element, out in zip(batch, output)])\n",
    "        self.critic.critic_online.fit([state_array, action_array], output, verbose=0)\n",
    "\n",
    "        prev_state_tensor = tf.Variable(shape = prev_state_array.shape, initial_value = prev_state_array)\n",
    "        prev_action_tensor = tf.Variable(shape = prev_action_array.shape, initial_value = prev_action_array)\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as g:\n",
    "            g.watch(prev_action_tensor) \n",
    "            g.watch(prev_state_tensor)\n",
    "            value = self.critic.call(prev_state_tensor, prev_action_tensor)\n",
    "            action = self.actor.actor(prev_state_tensor)\n",
    "            \n",
    "        gradient = -tf.squeeze(g.gradient(value, prev_action_tensor))\n",
    "        gradient = tf.cast(gradient, tf.float32)\n",
    "        gradient_actor = g.gradient(action, self.actor.actor.trainable_weights, gradient)\n",
    "        gradient_actor = list(map(lambda x: tf.math.divide(x, batch_size), gradient_actor))\n",
    "        self.optimizer.apply_gradients(zip(gradient_actor, self.actor.actor.trainable_weights))\n",
    "        self.critic.merge_networks(self.tau)\n",
    "\n",
    "        if self.step%self.save_frequency == 0:\n",
    "            self.save_networks()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_PARAMS = {\n",
    "\t\"output_range\": 1,\n",
    "\t\"actor_hidden_layers\": [60, 16],\n",
    "\t\"critic_hidden_layers\": [60, 16],\n",
    "\t\"state_dimensions\": 30,\n",
    "\t\"action_dimensions\": 30,\n",
    "\t\"critic_optimizer\": tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "\t\"actor_optimizer\": tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "\t\"batch_size\": 64,\n",
    "\t\"buffer_size\":1000000,\n",
    "\t\"discount\": 0.99,\n",
    "\t\"tau\": 0.001,\n",
    "\t\"save_frequency\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = [\"train/\" + f for f in os.listdir(\"train/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d8a262fd8c03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_stock_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/ITSP/MultipleStockDDPG/environment.py\u001b[0m in \u001b[0;36mcreate_stock_env\u001b[0;34m(locations, train)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_stock_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ITSP/MultipleStockDDPG/environment.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_stock_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   4991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4992\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4993\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4995\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1772\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1774\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "env = create_stock_env(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x = [pd.read_csv(f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
