{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, tiles3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateSpaceTiler:\n",
    "    def __init__(self, size, tilings, num_tiles, x_min, x_max, y_min, y_max):\n",
    "        self.iht = tiles3.IHT(size)\n",
    "        self.tilings = tilings\n",
    "        self.num_tiles = num_tiles\n",
    "        self.x_transform = lambda x: ((x - x_min)*self.num_tiles)/(x_max - x_min)\n",
    "        self.y_transform = lambda y: ((y - y_min)*self.num_tiles)/(y_max - y_min)\n",
    "    \n",
    "    def get_encoding(self, x, y):\n",
    "        return np.array(tiles3.tiles(self.iht, self.tilings, [self.x_transform(x), self.y_transform(y)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, params):\n",
    "        self.alpha_r = params.get(\"alpha_r\")\n",
    "        self.tilings = params.get(\"tilings\")\n",
    "        self.num_tiles = params.get(\"num_tiles\")\n",
    "        self.action_values = params.get(\"actions\")\n",
    "        self.iht_size = params.get(\"iht_size\")\n",
    "        self.alpha_w = params.get(\"alpha_w\")/self.tilings\n",
    "        self.alpha_theta =  params.get(\"alpha_t\")/self.tilings\n",
    "        self.tiler = StateSpaceTiler(self.iht_size,self.tilings, self.num_tiles, -np.pi, np.pi, -2*np.pi, 2*np.pi)\n",
    "        self.weights = np.zeros((self.iht_size, ))\n",
    "        self.policy = np.zeros((len(self.action_values), self.iht_size))\n",
    "        self.reward_mean = 0\n",
    "    \n",
    "    def get_reward(self):\n",
    "        return self.reward_mean\n",
    "    \n",
    "    def softmax_dist(self, state):\n",
    "        return np.sum(self.policy[:, state], axis=-1)\n",
    "    \n",
    "    def process(self, position):\n",
    "        sign = position/abs(position)\n",
    "        position = abs(position) % (2*np.pi)\n",
    "        if position > np.pi:\n",
    "            position -= 2*np.pi\n",
    "        return position*sign\n",
    "    \n",
    "    def softmax_prob(self, state):\n",
    "        dist = self.softmax_dist(state)\n",
    "        max_val = np.max(dist)\n",
    "        dist -= max_val\n",
    "        p = np.exp(dist)\n",
    "        return p/(np.sum(p))\n",
    "    def softmax_action(self, state):\n",
    "        return np.random.choice(len(self.action_values), p = self.softmax_prob(state))\n",
    "        \n",
    "    def agent_init(self, env_state):\n",
    "        position, self.velocity = env_state\n",
    "        self.position = self.process(position)\n",
    "        self.previous_state = self.tiler.get_encoding(self.position, self.velocity)\n",
    "        self.previous_action = self.softmax_action(self.previous_state)\n",
    "        \n",
    "        return self.action_values[self.previous_action] \n",
    "\n",
    "    def get_value(self, state):\n",
    "        return (np.sum(self.weights[state]))\n",
    "    \n",
    "    def agent_step(self, env_state, reward):\n",
    "        position, self.velocity = env_state\n",
    "        self.position = self.process(position)\n",
    "        current_state = self.tiler.get_encoding(self.position, self.velocity)\n",
    "        td_error = reward - self.reward_mean + self.get_value(current_state) - self.get_value(self.previous_state)\n",
    "        self.reward_mean = (self.reward_mean + self.alpha_r*td_error)/(1+self.alpha_r)\n",
    "        \n",
    "        self.weights[self.previous_state] += self.alpha_w*td_error\n",
    "        prob_dist = self.softmax_prob(self.previous_state)\n",
    "        for action in range(len(self.action_values)):\n",
    "            prob_scale = prob_dist[action]\n",
    "            if action == self.previous_action:\n",
    "                prob_scale = 1  - prob_dist[action]\n",
    "            self.policy[action][self.previous_state] += self.alpha_theta*td_error*prob_scale\n",
    "        \n",
    "        self.previous_state = current_state\n",
    "        self.previous_action = self.softmax_action(self.previous_state)\n",
    "        \n",
    "        return self.action_values[self.previous_action]\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_params = {\n",
    "    \"alpha_r\": 2**-6,\n",
    "    \"tilings\": 32,\n",
    "    \"num_tiles\": 8,\n",
    "    \"actions\": [-1, 0, 1],\n",
    "    \"iht_size\": 4096, \n",
    "    \"alpha_w\": 2,\n",
    "    \"alpha_t\": 2**(-2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(agent_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 100000\n",
    "env.reset()\n",
    "action = agent.agent_init(env.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value is -0.041679469914360286\n",
      "State is Position: -1.6748229696453092, Velocity -0.5921242069630042\n",
      "Value is -4.190547469490732\n",
      "State is Position: 3.0860103345577405, Velocity -0.07820619167138199\n",
      "Value is 89.60390885199628\n",
      "State is Position: -3.1084284221164493, Velocity -0.11324422997095229\n",
      "Value is -3043625.114698002\n",
      "State is Position: -3.0978462306437318, Velocity 0.246255506132444\n",
      "Value is -5735956.286900528\n",
      "State is Position: -2.815114998777849, Velocity 0.4432383046443114\n",
      "Value is 1390468.9590163052\n",
      "State is Position: -3.0628061968751243, Velocity -0.4501589709045849\n",
      "Value is 1301543.7987738084\n",
      "State is Position: -2.8150856313308923, Velocity 0.443116285263254\n",
      "Value is 488381.7196546548\n",
      "State is Position: -3.062836068247699, Velocity -0.45003704922838467\n",
      "Value is 458337.92057427776\n",
      "State is Position: -2.815056273662313, Velocity 0.44299423177871966\n",
      "Value is 158092.75284317255\n",
      "State is Position: -3.062865929793813, Velocity -0.44991509124498225\n",
      "Value is 196602.8291177508\n",
      "State is Position: -2.8150269257743568, Velocity 0.4428721442004861\n",
      "Value is 64122.96759635743\n",
      "State is Position: -3.062895781511053, Velocity -0.44979309696413966\n",
      "Value is 91182.46953350322\n",
      "State is Position: -2.814997587669278, Velocity 0.44275002253832885\n",
      "Value is 21770.785069612764\n",
      "State is Position: -3.062925623397008, Velocity -0.4496710663955928\n",
      "Value is 48223.507302719874\n",
      "State is Position: -2.8149682593493193, Velocity 0.4426278668019717\n",
      "Value is 12268.954436098273\n",
      "State is Position: -3.062955455449275, Velocity -0.449548999549046\n",
      "Value is 24602.46977291826\n",
      "State is Position: -2.8149389408167274, Velocity 0.4425056770011659\n",
      "Value is 4065.6354440622176\n",
      "State is Position: -3.0629852776654487, Velocity -0.44942689643424694\n",
      "Value is 12592.713237335389\n",
      "State is Position: -2.8149096320737548, Velocity 0.4423834531457614\n",
      "Value is 2363.2973971606134\n",
      "State is Position: -3.063015090043107, Velocity -0.44930475706099965\n",
      "Value is 6685.7989821466945\n",
      "State is Position: -2.8148803331226553, Velocity 0.44226119524546526\n",
      "Value is 1381.938856642662\n",
      "State is Position: -3.063044892579849, Velocity -0.44918258143898343\n",
      "Value is 3743.9955526963395\n",
      "State is Position: -2.814851043965663, Velocity 0.44213890331008776\n",
      "Value is 865.3660861205093\n",
      "State is Position: -3.063074685273276, Velocity -0.44906036957799833\n",
      "Value is 1997.2935816973452\n",
      "State is Position: -2.81482176460503, Velocity 0.44201657734940525\n",
      "Value is 608.9697929510511\n",
      "State is Position: -3.0631044681209647, Velocity -0.44893812148777007\n",
      "Value is 1093.2303722660545\n",
      "State is Position: -2.8147924950430068, Velocity 0.44189421737319584\n",
      "Value is 429.2517038751354\n",
      "State is Position: -3.0631342411205136, Velocity -0.44881583717808354\n",
      "Value is -721.1695944162359\n",
      "State is Position: -2.8147632352818346, Velocity 0.4417718233912116\n",
      "Value is 256.0586179837963\n",
      "State is Position: -3.0631640042695314, Velocity -0.4486935166586044\n",
      "Value is -394.78725544377494\n",
      "State is Position: -2.8147339853237434, Velocity 0.4416493954132148\n",
      "Value is 144.21169224953135\n",
      "State is Position: -3.063193757565614, Velocity -0.4485711599391763\n",
      "Value is -218.21886039676744\n",
      "State is Position: -2.8147047451709812, Velocity 0.44152693344904304\n",
      "Value is 81.91413266977304\n",
      "State is Position: -3.0632235010063504, Velocity -0.4484487670295641\n",
      "Value is -127.86761891827672\n",
      "State is Position: -2.814675514825798, Velocity 0.4414044375084672\n",
      "Value is 46.39164252466414\n",
      "State is Position: -3.0632532345893333, Velocity -0.44832633793951965\n",
      "Value is -73.18814326518314\n",
      "State is Position: -2.8146462942904305, Velocity 0.44128190760129804\n",
      "Value is 29.201640747718745\n",
      "State is Position: -3.0632829583121812, Velocity -0.448203872678813\n",
      "Value is -40.09657590398022\n",
      "State is Position: -2.8146170835671174, Velocity 0.4411593437372996\n",
      "Value is 14.350799635205966\n",
      "State is Position: -3.063312672172473, Velocity -0.44808137125720815\n",
      "Value is -25.667681560826264\n",
      "State is Position: -2.814587882658104, Velocity 0.4410367459262802\n",
      "Value is 6.645839025968966\n",
      "State is Position: -3.0633423761678165, Velocity -0.4479588336845135\n",
      "Value is -15.560141441335585\n",
      "State is Position: -2.814558691565618, Velocity 0.4409141141780241\n",
      "Value is 3.8549878048639883\n",
      "State is Position: -3.063372070295825, Velocity -0.4478362599704727\n",
      "Value is -10.139219233629802\n",
      "State is Position: -2.8145295102918992, Velocity 0.4407914485023455\n",
      "Value is 1.6524514400260402\n",
      "State is Position: -3.063401754554079, Velocity -0.4477136501249039\n",
      "Value is -6.352689645467454\n",
      "State is Position: -2.8145003388392045, Velocity 0.4406687489090819\n",
      "Value is -0.30904790531410176\n",
      "State is Position: -3.0634314289401887, Velocity -0.44759100415762054\n",
      "Value is -4.691412977905615\n",
      "State is Position: -2.8144711772097564, Velocity 0.4405460154080175\n",
      "Value is -1.3617304295195638\n",
      "State is Position: -3.0634610934517577, Velocity -0.4474683220783436\n",
      "Value is -4.025696891658665\n",
      "State is Position: -2.814442025405782, Velocity 0.44042324800890453\n",
      "Value is -1.8879027509752173\n",
      "State is Position: -3.0634907480863993, Velocity -0.4473456038968889\n",
      "Value is -3.5360979385859603\n",
      "State is Position: -2.8144128834295246, Velocity 0.4403004467216322\n",
      "Value is -2.2376383205769965\n",
      "State is Position: -3.0635203928417054, Velocity -0.44722284962306924\n",
      "Value is -3.225436732789754\n",
      "State is Position: -2.814383751283226, Velocity 0.44017761155597374\n",
      "Value is -2.3640523133142177\n",
      "State is Position: -3.0635500277152876, Velocity -0.44710005926664453\n",
      "Value is -3.119406613925735\n",
      "State is Position: -2.8143546289691, Velocity 0.44005474252167764\n",
      "Value is -2.4651007401303726\n",
      "State is Position: -3.06357965270476, Velocity -0.4469772328374491\n",
      "Value is -3.0501459211029935\n",
      "State is Position: -2.814325516489394, Velocity 0.43993183962865445\n",
      "Value is -2.5854958481853694\n",
      "State is Position: -3.0636092678077222, Velocity -0.4468543703452689\n",
      "Value is -3.0002528727828093\n",
      "State is Position: -2.8142964138463307, Velocity 0.43980890288668384\n",
      "Value is -2.617296789992244\n",
      "State is Position: -3.0636388730217963, Velocity -0.44673147179989847\n",
      "Value is -2.9263228236365944\n",
      "State is Position: -2.8142673210421365, Velocity 0.43968593230558384\n",
      "Value is -2.6467151984243174\n",
      "State is Position: -3.063668468344575, Velocity -0.44660853721120514\n",
      "Value is -2.93261916915275\n",
      "State is Position: -2.8142382380790565, Velocity 0.4395629278952203\n",
      "Value is -2.6569268663598105\n",
      "State is Position: -3.0636980537736775, Velocity -0.44648556658895905\n",
      "Value is -2.9226926876615438\n",
      "State is Position: -2.814209164959312, Velocity 0.4394398896653773\n",
      "Value is -2.6437979097992574\n",
      "State is Position: -3.0637276293067006, Velocity -0.44636255994301477\n",
      "Value is -2.9284629723787865\n",
      "State is Position: -2.8141801016851415, Velocity 0.4393168176259222\n",
      "Value is -2.5955561509802605\n",
      "State is Position: -3.0637571949412647, Velocity -0.44623951728314404\n",
      "Value is -2.9400043879115767\n",
      "State is Position: -2.814151048258758, Velocity 0.43919371178661726\n",
      "Value is -2.5789747096742124\n",
      "State is Position: -3.0637867506749856, Velocity -0.44611643861918093\n",
      "Value is -2.9292282676815042\n",
      "State is Position: -2.814122004682399, Velocity 0.43907057215733575\n",
      "Value is -2.650920870833228\n",
      "State is Position: -3.0638162965054714, Velocity -0.44599332396096286\n",
      "Value is -2.846237197689712\n",
      "State is Position: -2.8140929709582876, Velocity 0.43894739874790834\n",
      "Value is -2.7087930324558855\n",
      "State is Position: -3.0638458324303417, Velocity -0.44587017331831014\n",
      "Value is -2.817624813585261\n",
      "State is Position: -2.814063947088642, Velocity 0.4388241915682063\n",
      "Value is -2.713567165075782\n",
      "State is Position: -3.0638753584472065, Velocity -0.4457469867010521\n",
      "Value is -2.828260958488361\n",
      "State is Position: -2.814034933075693, Velocity 0.43870095062800885\n",
      "Value is -2.7389131449031288\n",
      "State is Position: -3.063904874553687, Velocity -0.44562376411903504\n",
      "Value is -2.8450651973874543\n",
      "State is Position: -2.81400592892166, Velocity 0.43857767593718067\n",
      "Value is -2.814837796408882\n",
      "State is Position: -3.063934380747397, Velocity -0.44550050558212606\n",
      "Value is -2.8697305467483445\n",
      "State is Position: -2.8139769346287786, Velocity 0.4384543675056134\n",
      "Value is -2.8224424378676143\n",
      "State is Position: -3.0639638770259428, Velocity -0.44537721110013284\n",
      "Value is -2.908597649171918\n",
      "State is Position: -2.813947950199262, Velocity 0.4383310253431075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value is -2.849204060265704\n",
      "State is Position: -3.063993363386954, Velocity -0.44525388068290683\n",
      "Value is -2.910970184583251\n",
      "State is Position: -2.8139189756353318, Velocity 0.4382076494595742\n",
      "Value is -2.8468605403696476\n",
      "State is Position: -3.064022839828041, Velocity -0.4451305143403398\n",
      "Value is -2.9676842042018046\n",
      "State is Position: -2.8138900109392226, Velocity 0.43808423986480943\n",
      "Value is -2.8476368839363038\n",
      "State is Position: -3.0640523063468197, Velocity -0.4450071120822293\n",
      "Value is -2.9078850624415145\n",
      "State is Position: -2.8138610561131467, Velocity 0.4379607965686937\n",
      "Value is -2.8206820970685134\n",
      "State is Position: -3.064081762940905, Velocity -0.4448836739184361\n",
      "Value is -2.8737118586133943\n",
      "State is Position: -2.8138321111593223, Velocity 0.43783731958098043\n",
      "Value is -2.807405790081485\n",
      "State is Position: -3.0641112096079546, Velocity -0.44476019985873805\n",
      "Value is -2.867121012741098\n",
      "State is Position: -2.8138031760799525, Velocity 0.43771380891160944\n",
      "Value is -2.795145449862641\n",
      "State is Position: -3.0641406463455607, Velocity -0.44463668991307465\n",
      "Value is -2.8509169680904316\n",
      "State is Position: -2.8137742508772634, Velocity 0.43759026457043015\n",
      "Value is -2.7929493222372903\n",
      "State is Position: -3.0641700731513577, Velocity -0.44451314409133197\n",
      "Value is -2.8169827967728414\n",
      "State is Position: -2.813745335553475, Velocity 0.4374666865673289\n",
      "Value is -2.7961717421930756\n",
      "State is Position: -3.0641994900229723, Velocity -0.44438956240329824\n"
     ]
    }
   ],
   "source": [
    "x_points = []\n",
    "y_points = []\n",
    "for _ in range(num_steps):\n",
    "    observation, reward, done, info = env.step([action])\n",
    "    env.render()\n",
    "    action = agent.agent_step(env.state, reward)\n",
    "    if _ % 1000 == 0:\n",
    "        print (\"Value is {0}\".format(agent.get_reward()))\n",
    "        print (\"State is Position: {0}, Velocity {1}\".format(agent.position, agent.velocity))\n",
    "        x_points.append(_/1000)\n",
    "        y_points.append(agent.get_reward())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
